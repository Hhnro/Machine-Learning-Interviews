{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "### Customize your dataset\n",
    "Basics\n",
    "- `__len__`: length of the dataset\n",
    "- `__getitem__`: get the $i$-th item of the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da4bc1af409caac2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Example(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.data = pd.read_csv(file_name).to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.data[:, :-1]\n",
    "        label = self.data[:, -1]\n",
    "        return feature, label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b07ea82b7609aca4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data with built-in functions\n",
    "\n",
    "For example, suppose you have a folder with images. Then you can use `ImageFolder` from `torchvision`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46463106c1dd7682"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Write transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize the images to 64x64\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0d5575881c181cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "138ad6224d7969e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4d8f376df62348a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, (features, labels) in enumerate(train_dataloader):\n",
    "    print(f\"Features shape: {features.shape}, Labels shape: {labels.shape}\")\n",
    "    # (64, feature_dim)  # (64, label_dim)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65b17d5bb61e246a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fded239e34041e25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
